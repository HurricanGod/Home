# <a name="top">数据统计</a>





-----

### 数据统计平台介绍



|        | 功能                               | 优点                                       | 缺点                                  | 体验链接 |      |
| :----- | :------------------------------- | :--------------------------------------- | :---------------------------------- | :--- | :--- |
| 百度统计   | 1. 基础统计<br/>2. 运营分析<br/>3. 数据可视化 |                                          |                                     |      |      |
|        |                                  |                                          |                                     |      |      |
| 腾讯移动分析 | 1. 基础统计<br/>2. 运营分析<br/>3. 数据可视化 | 1. 接入服务方便，只需要集成一段js sdk<br/>2. 比较专注于错误统计 |                                     |      |      |
|        |                                  |                                          |                                     |      |      |
| 神策     | 1. 基础统计<br/>2. 运营分析<br/>3. 数据可视化 | 1. 支持二次开发<br/>2. 提供私有部署版，可以提供用户专属数据仓库<br/>3. 提供的用户行为数据统计分析更全面<br/>4. 支持客户端和服务端埋点 | 超大流量的极端情况下可能会丢失一小部分数据，并且可能对业务造成一定影响 |      |      |
|        |                                  |                                          |                                     |      |      |

**优点**：

+ 第三方平台可以快速满足现有的**部分数据统计**需求，减少开发周期
+ 数据可视化，实时查看数据统计，并且还有用户分析、设备统计、运营分析等功能
+ 使用第三方数据统计平台可以减少服务器的压力，减少运维成本





**缺点**：

+ 使用第三方平台进行数据统计存在敏感数据问题
+ 第三方数据统计平台存在数据安全性问题（可能存在数据泄漏，丢失的风险）
+ 不能满足所有的业务数据统计

----
### 数据统计平台主流架构

+ 离线批处理数据统计架构

![](https://github.com/HurricanGod/Home/blob/master/kafka/img/statistic-static.jpg)





+ 在线流式处理实时数据统计架构

![](https://github.com/HurricanGod/Home/blob/master/kafka/img/statistic-storm.jpg)

**系统架构**：

+ 收集层`Agent` —— 采用`flume`进行日志收集，每个机器部署一个进程，负责对Web日志的收集工作
+ 汇总层`Collector` —— 负责接收`Agent`层发送的日志，采用负载均衡的策略将`Agent`层的日志均匀分发在`Collector`上，汇总决定日志流向
+ 处理层 —— 负责接收`Collector`层的日志，使用Kafka集群缓冲数据并使用Storm进行实时数据计算



`flume` ： 一个分布式的数据收集系统,具有高可靠、高可用、事务管理、失败重启、聚合和传输等功能。

核心概念：
+ event
> flume 的数据流由事件 (event) 贯穿始终。`event` 是 flume 的**基本数据单位**，它携带日志数据并且携带数据的头信息， `event` 由 agent 外部的 source 生成，当 source 捕获事件后会进行特定的格式化，然后 source 会把事件推入 channel 中
+ source
> source 是数据的收集端，负责将数据捕获后进行特殊的格式化，将数据封装到 event 里，然后将事件推入 channel 中
+ channel
> channel 是连接 source 和 sink 的组件，可以将它看做一个数据缓冲区（数据队列），可以将事件暂存到内存中也可以持久化到本地磁盘上， 直到 sink 处理完该事件。两个较为常用是`MemoryChannel` 和 `FileChannel`
+ agent
> flume 的核心是 agent。agent 是一个 java 进程,运行在日志收集端,通过 agent 接收日志,然后暂存起来,再发送到目的地。 每台机器运行一个 agent。 agent 里面可以包含多个 source，channel，sink。
+ sink
> sink 从 channel 中取出事件，然后将数据发到别处，可以向文件系统、数据库、hadoop、kafka，也可以是其他 agent 的 source



----
### 未来数据统计架构扩展思考
目前应用每秒产生的数据量不大，单机Kafka可以轻松应对。但作为基础的数据统计服务，未来会有越来越多的项目依赖该服务可能会存在以下问题：

+ 当并发量大时往Kafka发送的数据是否能够快速写入，吞吐量是否会成为瓶颈
+ 单机Kafka宕机是否会影响依赖数据统计服务的业务
+ 产生的消息过多是否能够及时消费，硬件资源是否足够（CPU、磁盘）
+ 数据统计服务是否会与业务有耦合，比如：每次需要数据统计时都要在项目中加入Kafka的依赖，然后往Kafka发消息进行数据统计
+ 升级Kafka版本是否会对依赖数据统计业务产生影响

